{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Using SKLL to Test Models/Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mulhollandm2/reviews_project/reviewer_experience_prediction/ipython_notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's find out where we are, first, and then see what models we have\n",
    "from os import getcwd, listdir\n",
    "getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['working',\n",
       " 'results',\n",
       " 'README',\n",
       " 'models',\n",
       " '.gitignore',\n",
       " 'arff_files_original_values',\n",
       " 'data',\n",
       " 'reports',\n",
       " 'config',\n",
       " 'logs',\n",
       " 'predictions',\n",
       " '.git',\n",
       " '.ipynb_checkpoints',\n",
       " 'ipython_notebooks',\n",
       " 'test',\n",
       " 'reviews_env',\n",
       " 'src',\n",
       " 'util',\n",
       " 'arff_files_collapsed_values',\n",
       " 'Makefile']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os.path import dirname, join\n",
    "listdir(dirname(getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arma_3_first500.train_Arma_3_first500_RescaledSVR.model\n",
      "Football_Manager_2015.train_Football_Manager_2015_RescaledSVR.model\n",
      "Football_Manager_2015.RSVRquadr.train_Football_Manager_2015_RescaledSVR.model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is a \"models\" directory that contains model files that we can\n",
    "# try to open with SKLL and use here\n",
    "# Now let's see what models we have (because models consist of many\n",
    "# files, let's just get the one with \".model\" as a suffix)\n",
    "from os.path import join\n",
    "[print(d) for d in listdir(join(dirname(getcwd()),\n",
    "                                'models')) if d.endswith('.model')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alright, so we'll use the Football_Manager_2015 model\n",
    "l = skll.Learner.from_file(join(dirname(getcwd()),\n",
    "                                'models',\n",
    "                                'Football_Manager_2015.train_Football_Manager_2015_RescaledSVR.model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# According to the documentation for skll.Learner objects, they have\n",
    "# a 'predict' method that requires an argument that is an object of\n",
    "# type FeatureSet, so we'll try to do that next\n",
    "l.predict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We are going to need to get some example data at some point,\n",
    "# so let's just do it right now\n",
    "import pymongo\n",
    "connection_string = 'mongodb://localhost:27017'\n",
    "connection = pymongo.MongoClient(connection_string)\n",
    "db = connection['reviews_project']\n",
    "reviewdb = db['reviews']\n",
    "reviewdb.write_concern['w'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'game': 'Football_Manager_2015', 'hours': 440.0, 'review': 'LOVING THE BETA CANT WAIT FOR FULL GAME ON THE 7TH', 'partition': 'test', 'hours_bin': 5, 'appid': '295270', '_id': ObjectId('5554f294c134cf3ebe2f5009')}\n"
     ]
    }
   ],
   "source": [
    "r1 = reviewdb.find_one({'game': 'Football_Manager_2015',\n",
    "                        'partition': 'test'})\n",
    "print(r1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# So we have an example test review and now we can work on\n",
    "# getting it into an object that can be passed to the prediction\n",
    "# function\n",
    "# But, first we will need to calculate all the features\n",
    "import sys\n",
    "sys.path.append('/home/mulhollandm2/reviews_project/reviewer_experience_prediction/')\n",
    "from src.feature_extraction import Review, extract_features_from_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prints out the documentation for this class that is part of\n",
    "# our code\n",
    "r1_review_obj = Review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1_review_obj = Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from spacy.en import English\n",
    "spaCy_nlp = English()\n",
    "r1_review_obj = Review(r1['review'],\n",
    "                       float(r1['hours_bin']), # using bins, i.e.,\n",
    "                                               # collapsed, form of\n",
    "                                               # the hours played\n",
    "                                               # value\n",
    "                       r1['game'],\n",
    "                       r1['appid'],\n",
    "                       spaCy_nlp,\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Let's take a look at the object\n",
    "print(r1_review_obj.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['appid',\n",
       " 'get_entities_from_spaCy',\n",
       " 'get_token_features_from_spaCy',\n",
       " 'hours_played',\n",
       " 'length',\n",
       " 'lower',\n",
       " 'norm',\n",
       " 'normalize',\n",
       " 'orig',\n",
       " 'spaCy_annotations',\n",
       " 'spaCy_sents',\n",
       " 'tags',\n",
       " 'tokens']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's the full list of attributes that are contained in each\n",
    "# Review object (attributes being variables or methods)\n",
    "[a for a in dir(r1_review_obj) if not a.startswith('__')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['loving', 'the', 'beta', 'can', 'not', 'wait', 'for', 'full', 'game', 'on', 'the', '7th']]\n"
     ]
    }
   ],
   "source": [
    "print(r1_review_obj.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With the processed representations of the review text, now we\n",
    "# can proceed to extract features\n",
    "# Let's see the documentation first\n",
    "r1_features = extract_features_from_review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r1_features = extract_features_from_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' 7': 1,\n",
       " ' 7T': 1,\n",
       " ' 7TH': 1,\n",
       " ' B': 1,\n",
       " ' BE': 1,\n",
       " ' BET': 1,\n",
       " ' BETA': 1,\n",
       " ' C': 1,\n",
       " ' CA': 1,\n",
       " ' CAN': 1,\n",
       " ' CANT': 1,\n",
       " ' F': 2,\n",
       " ' FO': 1,\n",
       " ' FOR': 1,\n",
       " ' FOR ': 1,\n",
       " ' FU': 1,\n",
       " ' FUL': 1,\n",
       " ' FULL': 1,\n",
       " ' G': 1,\n",
       " ' GA': 1,\n",
       " ' GAM': 1,\n",
       " ' GAME': 1,\n",
       " ' O': 1,\n",
       " ' ON': 1,\n",
       " ' ON ': 1,\n",
       " ' ON T': 1,\n",
       " ' T': 2,\n",
       " ' TH': 2,\n",
       " ' THE': 2,\n",
       " ' THE ': 2,\n",
       " ' W': 1,\n",
       " ' WA': 1,\n",
       " ' WAI': 1,\n",
       " ' WAIT': 1,\n",
       " '6': 1,\n",
       " '7T': 1,\n",
       " '7TH': 1,\n",
       " '7th': 1,\n",
       " '7th:the': 1,\n",
       " 'A ': 1,\n",
       " 'A C': 1,\n",
       " 'A CA': 1,\n",
       " 'A CAN': 1,\n",
       " 'AI': 1,\n",
       " 'AIT': 1,\n",
       " 'AIT ': 1,\n",
       " 'AIT F': 1,\n",
       " 'AM': 1,\n",
       " 'AME': 1,\n",
       " 'AME ': 1,\n",
       " 'AME O': 1,\n",
       " 'AN': 1,\n",
       " 'ANT': 1,\n",
       " 'ANT ': 1,\n",
       " 'ANT W': 1,\n",
       " 'BE': 1,\n",
       " 'BET': 1,\n",
       " 'BETA': 1,\n",
       " 'BETA ': 1,\n",
       " 'CA': 1,\n",
       " 'CAN': 1,\n",
       " 'CANT': 1,\n",
       " 'CANT ': 1,\n",
       " 'E ': 3,\n",
       " 'E 7': 1,\n",
       " 'E 7T': 1,\n",
       " 'E 7TH': 1,\n",
       " 'E B': 1,\n",
       " 'E BE': 1,\n",
       " 'E BET': 1,\n",
       " 'E O': 1,\n",
       " 'E ON': 1,\n",
       " 'E ON ': 1,\n",
       " 'ET': 1,\n",
       " 'ETA': 1,\n",
       " 'ETA ': 1,\n",
       " 'ETA C': 1,\n",
       " 'FO': 1,\n",
       " 'FOR': 1,\n",
       " 'FOR ': 1,\n",
       " 'FOR F': 1,\n",
       " 'FU': 1,\n",
       " 'FUL': 1,\n",
       " 'FULL': 1,\n",
       " 'FULL ': 1,\n",
       " 'G ': 1,\n",
       " 'G T': 1,\n",
       " 'G TH': 1,\n",
       " 'G THE': 1,\n",
       " 'GA': 1,\n",
       " 'GAM': 1,\n",
       " 'GAME': 1,\n",
       " 'GAME ': 1,\n",
       " 'HE': 2,\n",
       " 'HE ': 2,\n",
       " 'HE 7': 1,\n",
       " 'HE 7T': 1,\n",
       " 'HE B': 1,\n",
       " 'HE BE': 1,\n",
       " 'IN': 1,\n",
       " 'ING': 1,\n",
       " 'ING ': 1,\n",
       " 'ING T': 1,\n",
       " 'IT': 1,\n",
       " 'IT ': 1,\n",
       " 'IT F': 1,\n",
       " 'IT FO': 1,\n",
       " 'L ': 1,\n",
       " 'L G': 1,\n",
       " 'L GA': 1,\n",
       " 'L GAM': 1,\n",
       " 'LL': 1,\n",
       " 'LL ': 1,\n",
       " 'LL G': 1,\n",
       " 'LL GA': 1,\n",
       " 'LO': 1,\n",
       " 'LOV': 1,\n",
       " 'LOVI': 1,\n",
       " 'LOVIN': 1,\n",
       " 'ME': 1,\n",
       " 'ME ': 1,\n",
       " 'ME O': 1,\n",
       " 'ME ON': 1,\n",
       " 'N ': 1,\n",
       " 'N T': 1,\n",
       " 'N TH': 1,\n",
       " 'N THE': 1,\n",
       " 'NG': 1,\n",
       " 'NG ': 1,\n",
       " 'NG T': 1,\n",
       " 'NG TH': 1,\n",
       " 'NT': 1,\n",
       " 'NT ': 1,\n",
       " 'NT W': 1,\n",
       " 'NT WA': 1,\n",
       " 'ON': 1,\n",
       " 'ON ': 1,\n",
       " 'ON T': 1,\n",
       " 'ON TH': 1,\n",
       " 'OR': 1,\n",
       " 'OR ': 1,\n",
       " 'OR F': 1,\n",
       " 'OR FU': 1,\n",
       " 'OV': 1,\n",
       " 'OVI': 1,\n",
       " 'OVIN': 1,\n",
       " 'OVING': 1,\n",
       " 'R ': 1,\n",
       " 'R F': 1,\n",
       " 'R FU': 1,\n",
       " 'R FUL': 1,\n",
       " 'T ': 2,\n",
       " 'T F': 1,\n",
       " 'T FO': 1,\n",
       " 'T FOR': 1,\n",
       " 'T W': 1,\n",
       " 'T WA': 1,\n",
       " 'T WAI': 1,\n",
       " 'TA': 1,\n",
       " 'TA ': 1,\n",
       " 'TA C': 1,\n",
       " 'TA CA': 1,\n",
       " 'TH': 3,\n",
       " 'THE': 2,\n",
       " 'THE ': 2,\n",
       " 'THE 7': 1,\n",
       " 'THE B': 1,\n",
       " 'UL': 1,\n",
       " 'ULL': 1,\n",
       " 'ULL ': 1,\n",
       " 'ULL G': 1,\n",
       " 'VI': 1,\n",
       " 'VIN': 1,\n",
       " 'VING': 1,\n",
       " 'VING ': 1,\n",
       " 'WA': 1,\n",
       " 'WAI': 1,\n",
       " 'WAIT': 1,\n",
       " 'WAIT ': 1,\n",
       " 'beta': 1,\n",
       " 'beta can': 1,\n",
       " 'beta:the': 1,\n",
       " 'can': 1,\n",
       " 'can not': 1,\n",
       " 'can:loving': 1,\n",
       " 'can:not': 1,\n",
       " 'can:wait': 1,\n",
       " 'for': 1,\n",
       " 'for full': 1,\n",
       " 'for:game': 1,\n",
       " 'full': 1,\n",
       " 'full game': 1,\n",
       " 'game': 1,\n",
       " 'game on': 1,\n",
       " 'game:full': 1,\n",
       " 'loving': 1,\n",
       " 'loving the': 1,\n",
       " 'loving:beta': 1,\n",
       " 'not': 1,\n",
       " 'not wait': 1,\n",
       " 'on': 1,\n",
       " 'on the': 1,\n",
       " 'on:7th': 1,\n",
       " 'the': 2,\n",
       " 'the 7th': 1,\n",
       " 'the beta': 1,\n",
       " 'wait': 1,\n",
       " 'wait for': 1,\n",
       " 'wait:for': 1,\n",
       " 'wait:on': 1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1_features = extract_features_from_review(r1_review_obj)\n",
    "r1_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n"
     ]
    }
   ],
   "source": [
    "print(len(r1_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As you can see, even for a short review, there are 210\n",
    "# features present\n",
    "# Now, how do we put this in an object that we can pass to the\n",
    "# prediction function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 0, 1)\n"
     ]
    }
   ],
   "source": [
    "# For one thing, I just want to re-check the version of SKLL\n",
    "# being used\n",
    "print(skll.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Alright, great, we are using version 1.0.1, as I thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skll.data.featureset import FeatureSet\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r1_fs = FeatureSet('single_review_Football_Manager_2015',\n",
    "                   np.array([str(r1['_id'])],\n",
    "                            dtype=np.chararray),\n",
    "                   np.array([float(r1['hours_bin'])],\n",
    "                            dtype=np.float32),\n",
    "                   [r1_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x210 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 210 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what r1_fs is\n",
    "r1_fs.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5554f294c134cf3ebe2f5009'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1_fs.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'single_review_Football_Manager_2015'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1_fs.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:skll.learner:There is mismatch between the training model features and the data passed to predict.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.94951896])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ok, let's try to predict the label with our learner\n",
    "l.predict(r1_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does the prediction compare with the actual value? Let's\n",
    "# see...\n",
    "r1_review_obj.hours_played"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So, it is off by a few. Remember, this is a 10-point scale, so\n",
    "# the difference isn't quite as drastic as it might initially appear,\n",
    "# but it is quite different"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
